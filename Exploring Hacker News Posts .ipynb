{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we are going to analyse a data set of submissions to a popular technology site [Hacker News](https://news.ycombinator.com/). Hacker News is a similar to reddit site where users-submitted stories, known as \"posts\", are voted and commented upon. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "Analysing the data set of Hacker News post we´ll pay a special attention to the posts whose titles begin with either `Ask HN` or `Show HN` where users either ask the site community a specific question or shara with the community  a project, product, or just generally something interesting.\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    " - Do `Ask HN` or `Show HN` receive more comments on average?\n",
    " - Do `Ask HN` or `Show HN` receive more points on average?\n",
    " - Do posts created at a certain time receive more comments on average?\n",
    " - Do posts created at a certain time receive more points on average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). But we are going to work with a reduced version of it, prepared by Dataques team for studying purposes. This file can be downloaded [here](https://app.dataquest.io/m/356/guided-project%3A-exploring-hacker-news-posts/1/introduction). The Data quest team has reducedthe original data set from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "Let's start by opening the two data sets and then continue with exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to explore the data set, first we create a function named explore_data() which allows us to print rows in a readable way. Also we add it an optional feature to show the number of rows and columns for any data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "Number of rows: 20100\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new(empty) line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "print(hn_header)\n",
    "print('\\n')\n",
    "explore_data(hn, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each entry contains the unique id of the post, the title, the URL-address, the numbers of points and comments recieved, the author and the date the post was created. For the goals of this project we are going to work more with the `title`, `num_comments`, `num_points` and `created at` columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Ask HN and Show HN posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we´re going to isolate posts which begin with either `Ask HN` or `Show HN` into two separate data sets. Then, we´ll explore the 'Ask HN' and 'Show HN' data sets and the data set with the remainder posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts:\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "Number of rows: 1744\n",
      "Number of columns: 7\n",
      "\n",
      "\n",
      "Show posts:\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "Number of rows: 1162\n",
      "Number of columns: 7\n",
      "\n",
      "\n",
      "Other posts:\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "Number of rows: 17194\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    title_lc = title.lower()\n",
    "    if title_lc.startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title_lc.startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print('Ask posts:')\n",
    "explore_data(ask_posts, 0, 2, True)\n",
    "print('\\n')\n",
    "\n",
    "print('Show posts:')\n",
    "explore_data(show_posts, 0, 2, True)\n",
    "print('\\n')\n",
    "\n",
    "print('Other posts:')\n",
    "explore_data(other_posts, 0, 2, True)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Average Amount of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having separated the `Ask HN` and `Show HN` posts we can calculate which of these types of posts recieves more comment on average. First, let´s create a function that allows us to calculate the average of any column of a data set, we´ll name it `avg_by_column()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_by_column (dataset, column_index):\n",
    "    total_count = 0\n",
    "    for row in dataset:\n",
    "        total_count += int(row[column_index])\n",
    "    avg_column = total_count / len(dataset) \n",
    "    return avg_column\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we´ll cheack what are the average comments number for the `Ask HN`, `Show HN` and the remainders posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for Ask HN posts: 14.04\n",
      "The average number of comments for Show HN posts: 10.32\n",
      "The average number of comments for Other posts: 26.87\n"
     ]
    }
   ],
   "source": [
    "template_str = \"The average number of comments for {type} posts: {avg:.2f}\"\n",
    "print(template_str.format(type = 'Ask HN', avg = avg_by_column(ask_posts, 4)))\n",
    "print(template_str.format(type = 'Show HN', avg = avg_by_column(show_posts, 4)))\n",
    "print(template_str.format(type = 'Other', avg = avg_by_column(other_posts, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the 'Ask HN' posts recieve on general more comments than the 'Show HN' posts. At the same time the 'Ask HN' posts recieve few less comments on average than the remainder posts.  Considering that we´ll focus on 'Ask HN' posts in the following steps where we´ll analyse if there´s an hour to create a post when the posts tend to recieve more comments than during the rest of the day. And we´ll compare the results with the posts which are neither 'Ask HN' nor 'Show HN'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Average Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the data in `created_at` column we´ll use the `datatime` module. First, we´ll create a function `total_by_hour()` which we are going to use to calculate the amount of posts created each hour of day and the number of comments or points (depending on which parameter we want to investigate) these posts recieved. The function will return a dictionary with the hours of day as the key values and the number of posts created at this hour together with total number of points or comments received as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': [251, 45],\n",
       " '13': [1253, 85],\n",
       " '10': [793, 59],\n",
       " '14': [1416, 107],\n",
       " '16': [1814, 108],\n",
       " '23': [543, 68],\n",
       " '12': [687, 73],\n",
       " '17': [1146, 100],\n",
       " '15': [4477, 116],\n",
       " '21': [1745, 109],\n",
       " '20': [1722, 80],\n",
       " '02': [1381, 58],\n",
       " '18': [1439, 109],\n",
       " '03': [421, 54],\n",
       " '05': [464, 46],\n",
       " '19': [1188, 110],\n",
       " '01': [683, 60],\n",
       " '22': [479, 71],\n",
       " '08': [492, 48],\n",
       " '04': [337, 47],\n",
       " '00': [447, 55],\n",
       " '06': [397, 44],\n",
       " '07': [267, 34],\n",
       " '11': [641, 58]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the 'datetime' module with an alias 'dt'\n",
    "import datetime as dt\n",
    "\n",
    "def total_by_hour (dataset, column_index):\n",
    "    total_by_hour_dict = {}\n",
    "    for row in dataset:\n",
    "        #converting the string value to a 'datatime' object\n",
    "        created_at_str = row[6]\n",
    "        created_at_dt = dt.datetime.strptime(created_at_str, '%m/%d/%Y %H:%M')\n",
    "        \n",
    "        #retrieving the hour as a string\n",
    "        hour_str = created_at_dt.strftime('%H')\n",
    "        \n",
    "        column_value = int(row[column_index])\n",
    "        if hour_str not in total_by_hour_dict:\n",
    "            total_by_hour_dict[hour_str] = [column_value, 1]\n",
    "        else:\n",
    "            total_by_hour_dict[hour_str][0] += column_value\n",
    "            total_by_hour_dict[hour_str][1] += 1\n",
    "        \n",
    "        \n",
    "    return total_by_hour_dict\n",
    "    \n",
    "total_by_hour (ask_posts, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Average Number of Comments for 'Ask HN' posts by hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the average number of comments ask posts receive by hour created. We´ll keep the results in a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_by_hour(total_by_hour_dict):\n",
    "    avg_by_hour_list = []\n",
    "    for hour in total_by_hour_dict:\n",
    "        avg_by_hour_list.append([hour, total_by_hour_dict[hour][0] / total_by_hour_dict[hour][1]])\n",
    "    return avg_by_hour_list\n",
    "\n",
    "total_ask_comments_by_hour = total_by_hour(ask_posts, 4)\n",
    "avg_by_hour(total_ask_comments_by_hour)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read. We´ll create a special function to do it, thus we can use this function later when analyzing number of points and comparing the results with the remainder posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "def top_5_sorted(avg_by_hour_list):\n",
    "    swap_avg_by_hour = []\n",
    "    for row in avg_by_hour_list:\n",
    "        swap_avg_by_hour.append([row[1], row[0]])\n",
    "        \n",
    "    sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "    return sorted_swap[:5]\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "template = \"{hour}:00: {avg_comments:.2f} average comments per post\"\n",
    "for avg, hr in top_5_sorted (avg_by_hour(total_ask_comments_by_hour)):\n",
    "        print(template.format(hour = hr, avg_comments = avg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Ask HN' posts created at 15:00 recieve the highest number of comments, the average number of comments for these posts is 38.59. The runner-up hour is 02:00 a.m., but the average number decreases almost by 60%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Results with the \"Other\" Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions created in the previous step, let´s see if the top 5 hours to post in order to get more comments are the same for \"Ask HN\" posts and the \"Other\" posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Other Posts Comments\n",
      "14:00: 32.33 average comments per post\n",
      "13:00: 30.90 average comments per post\n",
      "12:00: 30.35 average comments per post\n",
      "11:00: 29.59 average comments per post\n",
      "15:00: 29.52 average comments per post\n"
     ]
    }
   ],
   "source": [
    "other_comments_by_hour = total_by_hour(other_posts, 4)\n",
    "avg_other_comments_by_hour = avg_by_hour(other_comments_by_hour)\n",
    "final_other_comments = top_5_sorted(avg_other_comments_by_hour) \n",
    "\n",
    "print('Top 5 Hours for Other Posts Comments')\n",
    "\n",
    "template = \"{hour}:00: {avg_comments:.2f} average comments per post\"\n",
    "for avg, hr in final_other_comments:\n",
    "        print(template.format(hour = hr, avg_comments = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the posts of our 'control group' recieve more comments on average durinig the daytime from 11 a.m. to 3 p.m. with the top hour of 2 p.m. Also  there´s not much diference between the average comment rate during these 5 hours. If we compare these results with the results of \"Ask HN\" post, we can tell that although the average comment rate is almost 2 times less for \"Ask HN\" posts than for the \"Other\" posts, the \"Ask HN\" posts recieve more comments on average if created at its top hour (at 3 p.m. with 38.59 comments) than \"Other\" posts (its average is 26.87 with the maximum average number of comments 32.33 for the posts created at 2 p.m.).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Point Number for 'Ask HN' and 'Show HN' posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of points represented in the `num_point`column is  the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes. We can check which type of posts recieve more points on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of points for Ask HN posts: 15.06\n",
      "The average number of points for Show HN posts: 27.56\n",
      "The average number of points for Other posts: 55.41\n"
     ]
    }
   ],
   "source": [
    "template_str = \"The average number of points for {type} posts: {avg:.2f}\"\n",
    "print(template_str.format(type = 'Ask HN', avg = avg_by_column(ask_posts, 3)))\n",
    "print(template_str.format(type = 'Show HN', avg = avg_by_column(show_posts, 3)))\n",
    "print(template_str.format(type = 'Other', avg = avg_by_column(other_posts, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Show HN\" posts get more points on average than \"Ask HN\" but less than the \"Other\" posts. So, let´s focus further on the \"Show HN\" posts and compare the results with the \"Other\" posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Average Amount of Show Posts and Points by Hour Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Show Posts points\n",
      "23:00: 42.39 average points per post\n",
      "12:00: 41.69 average points per post\n",
      "22:00: 40.35 average points per post\n",
      "00:00: 37.84 average points per post\n",
      "18:00: 36.31 average points per post\n"
     ]
    }
   ],
   "source": [
    "show_points_by_hour = total_by_hour(show_posts, 3)\n",
    "avg_show_points_by_hour = avg_by_hour(show_points_by_hour)\n",
    "final_show_points = top_5_sorted(avg_show_points_by_hour) \n",
    "\n",
    "print('Top 5 Hours for Show Posts points')\n",
    "\n",
    "template = \"{hour}:00: {avg_points:.2f} average points per post\"\n",
    "for avg, hr in final_show_points:\n",
    "        print(template.format(hour = hr, avg_points = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Show HN\" posts get more points on average when published at 23:00, with the 12:00 as a runner-up. In general, the good hours to post if looking for more points are from 22:00 to 00:00 and also at 12:00 and at 18:00. Let´s compare now the results with the \"Other\" posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Other Posts points\n",
      "13:00: 62.53 average points per post\n",
      "14:00: 61.79 average points per post\n",
      "15:00: 60.54 average points per post\n",
      "10:00: 60.48 average points per post\n",
      "19:00: 60.01 average points per post\n"
     ]
    }
   ],
   "source": [
    "other_points_by_hour = total_by_hour(other_posts, 3)\n",
    "avg_other_points_by_hour = avg_by_hour(other_points_by_hour)\n",
    "final_other_points = top_5_sorted(avg_other_points_by_hour) \n",
    "\n",
    "print('Top 5 Hours for Other Posts points')\n",
    "\n",
    "template = \"{hour}:00: {avg_points:.2f} average points per post\"\n",
    "for avg, hr in final_other_points:\n",
    "        print(template.format(hour = hr, avg_points = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Other\" posts keep getting its best results when created during the daytime, with the best hour of 13:00 when each \"Other\" post gets 62.53 points on average.  \n",
    "\n",
    "In general the \"Show HN\" posts created at its top hour, 23:00, get quite more points than on average, but still the average number of points at the top hour is inferior to the average number of  points for \"Other\" posts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time zone aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour in the data set, accroding to the [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts,) is provided for the  Eastern Time in the US timezone (UTC -5:00). In order to be able to customize the results of this analysis, let´s create a function `change_time()` that adapts the results to a local timezone.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(final_list, timezone):\n",
    "    \"\"\"changes the hour in the final list to the timezone provided. \n",
    "    The timezone should be formatted as '+5' for the UTC+5:00, '-1' for the UTC-1:00\"\"\"\n",
    "    est_to_utc = dt.timedelta(hours=5)\n",
    "    utc_to_timezone = dt.timedelta(hours=abs(timezone))\n",
    "    final_list_timezone = []\n",
    "    for avg, hr in final_list:\n",
    "        hour_dt = dt.datetime.strptime(hr, \"%H\")\n",
    "        hour_dt_utc = hour_dt + est_to_utc\n",
    "        if timezone < 0:\n",
    "            hour_dt_timezone = hour_dt_utc - utc_to_timezone\n",
    "        else: \n",
    "            hour_dt_timezone = hour_dt_utc + utc_to_timezone\n",
    "        hour_timezone = hour_dt_timezone.strftime(\"%H:%M\")\n",
    "        final_list_timezone.append([avg, hour_timezone])\n",
    "    return final_list_timezone\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s check the top 5 hours to publish for the continental Spain (UTC+1:00)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments for UTC +1:00 timezone\n",
      "21:00:00: 38.59 average comments per post\n",
      "08:00:00: 23.81 average comments per post\n",
      "02:00:00: 21.52 average comments per post\n",
      "22:00:00: 16.80 average comments per post\n",
      "03:00:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "final_ask_comments = top_5_sorted (avg_by_hour(total_ask_comments_by_hour))\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments for UTC +1:00 timezone')\n",
    "\n",
    "template = \"{hour}:00: {avg_comments:.2f} average comments per post\"\n",
    "for avg, hr in change_time(final_ask_comments, +1):\n",
    "        print(template.format(hour = hr, avg_comments = avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments and the most points on average. \n",
    "\n",
    "Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est). The ask posts created at this time recieve even more comments on average than the other posts (neither ask nor show) created at the best hour for their category.\n",
    "\n",
    "If the goal is to get more points for a post, the post is better to be categorized as show post and created between 23:00 and 00:00 (11 pm est - 12 am est). Nevretheless, to maximize the ammount of points a post receives, we´d recommend to continue exploring the other posts category as it the one that recieve the most points on average when the post is created at top hours for its category.  \n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average. If it´s necessary to customize the results of completed analysis to a different time zone, we´ve created a function `change_time()`which allows us to do that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
